import os
import numpy as np
from sklearn import svm
from sklearn.metrics import accuracy_score
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from keras.optimizers import SGD
from keras.utils import to_categorical
import cv2
import matplotlib.pyplot as plt

# Function to load and preprocess the dataset
def load_dataset(data_dir):
    X = []
    y = []

    class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])

    # Map class names to integer labels
    class_to_label = {class_name: i for i, class_name in enumerate(class_names)}

    for class_name in class_names:
        class_path = os.path.join(data_dir, class_name)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)

            # Skip non-image files
            if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            # Preprocess the image (you might need to adjust this based on your actual preprocessing)
            # Example: read the image and resize it to (227, 227)
            img = cv2.imread(img_path)

            # Check if the image is loaded successfully
            if img is None:
                print(f"Error: Unable to read the image from path: {img_path}")
                continue

            img = cv2.resize(img, (227, 227))

            # Normalize pixel values to be between 0 and 1
            img = img / 255.0

            X.append(img)
            y.append(class_to_label[class_name])

    X = np.array(X)
    y = np.array(y)

    return X, y

# Specify the paths to your training and testing datasets
train_data_dir = '/content/drive/MyDrive/Face-Images/Face Images/Final Training Images'
test_data_dir = '/content/drive/MyDrive/Face-Images/Face Images/Final Testing Images'

# Load and preprocess the training dataset
X_train, y_train = load_dataset(train_data_dir)

# Load and preprocess the testing dataset
X_test, y_test = load_dataset(test_data_dir)

# Convert class indices to one-hot encoding
y_train_one_hot = to_categorical(y_train, num_classes=len(np.unique(y_train)))
y_test_one_hot = to_categorical(y_test, num_classes=len(np.unique(y_test)))

# Train SVM on the training set
X_train_flat = X_train.reshape(X_train.shape[0], -1)  # Flatten the images
svm_classifier = svm.SVC()
svm_classifier.fit(X_train_flat, y_train)

# Flatten the testing images
X_test_flat = X_test.reshape(X_test.shape[0], -1)

# Make predictions on the test set using SVM
y_pred_svm = svm_classifier.predict(X_test_flat)

# Evaluate SVM on the test set
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f'SVM Accuracy on Test Set: {accuracy_svm * 100:.2f}%')

# Fine-tune CNN on the training set
model = Sequential()

# AlexNet-like CNN architecture
model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation="relu", input_shape=(227, 227, 3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))

model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))

model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())

model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())

model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation="relu", padding="same"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))

model.add(Flatten())

model.add(Dense(4096, activation="relu"))
model.add(Dropout(0.5))

model.add(Dense(4096, activation="relu"))
model.add(Dropout(0.5))

model.add(Dense(4096, activation="relu"))
model.add(Dropout(0.5))

model.add(Dense(2048, activation="relu"))
model.add(Dropout(0.5))

model.add(Dense(16, activation='softmax'))

# Compile the CNN
optimizer = SGD(lr=0.0001)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Data Generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

batch_size = 16
training_set = train_datagen.flow(X_train, y_train_one_hot, batch_size=batch_size)
test_set = test_datagen.flow(X_test, y_test_one_hot, batch_size=batch_size)

# Training the CNN model
history = model.fit(
    training_set,
    steps_per_epoch=len(X_train) // batch_size,
    epochs=100,
    validation_data=test_set,
    validation_steps=len(X_test) // batch_size)

# Plotting training and validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plotting training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Evaluate the CNN on the test set
accuracy_cnn = model.evaluate(test_set, steps=len(X_test) // batch_size)[1]
print(f'CNN Accuracy on Test Set: {accuracy_cnn * 100:.2f}%')

# Load and preprocess the input image for testing
input_image_path = '/content/drive/MyDrive/Face-Images/Face Images/Final Testing Images/face10/1face10.jpg'
input_img = cv2.imread(input_image_path)

# Check if the image is loaded successfully
if input_img is None:
    print(f"Error: Unable to read the image from path: {input_image_path}")
else:
    print("Image loaded successfully.")

    # Resize the input image
    input_img = cv2.resize(input_img, (227, 227))
    input_img = input_img / 255.0
    input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension

    # Make prediction using the fine-tuned CNN
    prediction = model.predict(input_img)
    predicted_class = np.argmax(prediction)

    # Load class labels from the training dataset
    class_names = sorted([d for d in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, d))])

    # Map class indices to class labels
    class_labels = {i: class_name for i, class_name in enumerate(class_names)}

    # Map the predicted class index to the corresponding class label
    predicted_class_label = class_labels[predicted_class]

    print(f'Predicted Class: {predicted_class_label}')
